{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('website': venv)"
  },
  "interpreter": {
   "hash": "526c6d517c181ea8a90430c85bc56c6c81b52fe8bc1332055751a149542bc334"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Intro to Autoencoders in python \n",
    "\n",
    "Autoencoders are special types of neural networks that are often attributed to non-linear PCA (principal component analysis). Autoencoders have several use cases. In this blog post we will discuss autoencoders in the context of data quality. We will use autoencoders to detect outliers in data. For example, given an image of a handwrtten digit, an autoencoder first encodes the image into a lower dimensional latent space like PCA, then decodes the latent representation back to an image. Autoencoders can also be used for to compress images, they do this while minimizing the *reconstruction error*. \n",
    "\n",
    "The reconstruction error here means the difference (by some distance measure) between the actual image and reconstructed image.\n",
    "\n",
    "## Import libraries"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "source": [
    "## Loading the data\n",
    "The Fashon MNIST dataset is a very familiar data set that has been used in many tutorials to explain simple concepts about neural networks. We will do the same in this blog post.  Each image in the MNIST dataset is 28x28 pixels. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(60000, 28, 28)\n(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "(x_train, _), (x_test, _) = fashion_mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "\n",
    "\n",
    "def gen_image(arr):\n",
    "    two_d = (np.reshape(arr, (28, 28)) * 255).astype(np.uint8)\n",
    "    plt.imshow(two_d, interpolation='nearest')\n",
    "    return plt\n",
    "\n",
    "print (x_train.shape)\n",
    "print (x_test.shape)"
   ]
  },
  {
   "source": [
    "We have printed the dimension  of the train and test dataset,  there are 60k images in the training dataset and 10k in the test.\n",
    "We will define a very simple autoencoder which compresses (`encoder`)the input images into a 64 dimensional laten vector, and a `decoder`, that reconstructs the original image from the latent space. We define a simple class for this. The constructor of the class takes the dimension of the latent space.For the encoder, we will use `Tensoflow`'s `Sequential` API. We first flatten the images and then pass it to a dense layer. The decoder has one dense layer and then reshapes the image back to ther original dimension. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 64\n",
    "\n",
    "class Autoencoder(Model):\n",
    "  def __init__(self, latent_dim):\n",
    "    super(Autoencoder, self).__init__()\n",
    "    self.latent_dim = latent_dim   \n",
    "    self.encoder = tf.keras.Sequential([\n",
    "      layers.Flatten(),\n",
    "      layers.Dense(latent_dim, activation='relu'),\n",
    "    ])\n",
    "    self.decoder = tf.keras.Sequential([\n",
    "      layers.Dense(784, activation='sigmoid'),\n",
    "      layers.Reshape((28, 28))\n",
    "    ])\n",
    "\n",
    "  def call(self, x):\n",
    "    encoded = self.encoder(x)\n",
    "    decoded = self.decoder(encoded)\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantial the Autoencoder class\n",
    "autoencoder = Autoencoder(latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0239 - val_loss: 0.0134\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 2s 951us/step - loss: 0.0116 - val_loss: 0.0108\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 2s 941us/step - loss: 0.0100 - val_loss: 0.0096\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 2s 953us/step - loss: 0.0094 - val_loss: 0.0093\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 2s 983us/step - loss: 0.0092 - val_loss: 0.0092\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 2s 982us/step - loss: 0.0090 - val_loss: 0.0091\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0089 - val_loss: 0.0089\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 2s 989us/step - loss: 0.0088 - val_loss: 0.0089\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0088 - val_loss: 0.0089\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0087 - val_loss: 0.0088\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0145056c10>"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=10,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}